# Приложение: Математика для глубокого обучения
:label:`chap_appendix_math`

**Brent Werness** (*Amazon*), **Rachel Hu** (*Amazon*), и авторы этой книги

Одной из замечательных вещей современного глубокого обучения является то, что большую его часть можно понять и использовать без полного понимания лежащей в его основе математики. Это признак того, что область взрослеет. Подобно тому, как большинству разработчиков программного обеспечения больше не нужно беспокоиться о теории вычислимых функций, так и специалистам-практикам глубокого обучения не следует переживать о теоретических основах обучения с максимальным правдоподобием. 

Но мы еще не совсем там.

На практике вам иногда нужно понимать, как выбор архитектуры влияет на движение градиента, или на неявные предположения, которые вы делаете при обучении с определенной функцией потерь. Возможно, вам потребуется знать, что измеряет энтропия, и как это поможет вам понять, что в точности означает бит на символ в вашей модели. Все это требует более глубокого математического понимания.

В этом приложении вы найдете математические основы, необходимые для понимания основной теории современного глубокого обучения, но оно не является исчерпывающим. Мы гачнем с более глубокого изучения линейной алгебры и развовьем геометрическое понимание распространенных объектов и операций линейной алгебры, которые позволяют нам визуализировать результатя различных преобразований наших данных. Ключевой частью будут основы спектральных разложений.

Затем мы рассмотрим теорию дифференциального исчисления до того момента, чтобы понять почему градиент является направлением наибыстрейшего спуска и почему обратное распространение имеет такую форму. Далее мы обсудим интегральное исчисление в объеме достаточном для изучения нашей следующей темы - теории вероятностей.

Проблемы, которые часто встречаются на практике, не являются детерминированными, и поэтому нам нужен язык, чтобы говорить о неопределенных вещах. Мы рассматриваем теорию случайных величин и наиболее часто встречающиеся распределения, чтобы мы могли обсуждать модели с точки зрения теории вероятностей. Это обеспечивает основу для наивного байесовского классификатора являющегося методои вероятностной классификации.

С теорией вероятностей тесно связано изучение статистики. Хотя статистика - слишком большая область, чтобы вместиться в короткий раздел, мы представим фундаментальные концепции, о которых необходимо знать всем практикам машинного обучения, в частности: оценка и сравнение оценщиков, проведение тестов гипотез и построение доверительных интервалов.

Наконец мы перейдем к теории информации, которая представляет собой математическое исследование хранения и передачи информации. Она дает нам основной язык, с помощью которого мы можем количественно обсудить, сколько информации о предметной области содержится модель.

Взятые вместе, они составляют ядро математических концепций, необходимых для того, чтобы начать путь к глубокому пониманию глубокого обучения.

```toc
:maxdepth: 2

geometry-linear-algebraic-ops
eigendecomposition
single-variable-calculus
multivariable-calculus
integral-calculus
random-variables
maximum-likelihood
distributions
naive-bayes
statistics
information-theory
```